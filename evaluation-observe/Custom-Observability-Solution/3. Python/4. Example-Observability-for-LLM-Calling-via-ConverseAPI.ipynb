{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00307a86",
   "metadata": {},
   "source": [
    "# Observability with Amazon Bedrock Converse API\n",
    "\n",
    "The AWS Bedrock Converse API is a powerful tool for building conversational AI applications. It allows developers to create dynamic, multi-turn conversations with large language models (LLMs) hosted on AWS Bedrock. Here are some key benefits of using the Converse API:\n",
    "\n",
    "1. **Stateful Conversations**: The API maintains conversation context across multiple turns, allowing for more natural and coherent interactions.\n",
    "\n",
    "2. **Simplified Integration**: It provides a streamlined interface for integrating advanced language models into your applications without managing complex prompt engineering.\n",
    "\n",
    "3. **Customization**: Developers can customize the conversation flow, system prompts, and model parameters to suit specific use cases.\n",
    "\n",
    "4. **Scalability**: Being part of AWS Bedrock, it offers the scalability and reliability of AWS infrastructure.\n",
    "\n",
    "5. **Access to Multiple Models**: You can easily switch between different LLMs available on AWS Bedrock without changing your application code.\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, we'll demonstrates how to implement observability for the Amazon Bedrock Converse API using the custom observability solution. We'll use the `BedrockLogs` class from the `observability` module to track and log API calls, responses, and user feedback.\n",
    "\n",
    "### Prerequisite\n",
    "After successfully setting up the backend resources required using the provided `CloudFormation template` to gather necessary data on user requests, your custom metadata like latency, time to first token, tags, model responses, citations, and any other custom identifiers you would like to add (e.g., user_id/customer_id), you can now test if your observability architecture is working as expected and determine the latency introduced by adding this additional component to your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa331b",
   "metadata": {},
   "source": [
    "#### `Important Note`: \n",
    "\n",
    "##### 1. Please use your AWS configuration to fill in the `config.py` file before running the code \n",
    "\n",
    "##### 2: Make sure you have upgraded your boto3 version to have at least `1.34.126` version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ea2a3",
   "metadata": {},
   "source": [
    "### Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a02c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import string\n",
    "import random\n",
    "from uuid import uuid4\n",
    "\n",
    "# Custom observability module\n",
    "from observability import BedrockLogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ee875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your configuration values (make sure to create a config.py file with these values)\n",
    "from config import (\n",
    "    REGION, FIREHOSE_NAME, CRAWLER_NAME, MODEL_ARN,\n",
    "    EXPERIMENT_ID, CUSTOM_TAG, GUARDRAIL_ID, GUARDRAIL_VERSION,\n",
    "    MAX_TOKENS, TEMPERATURE, TOP_P\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8404aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BedrockLogs in Local mode with feedback variables\n",
    "bedrock_logs = BedrockLogs(delivery_stream_name='local', feedback_variables=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a137191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AWS clients\n",
    "boto3_session = boto3.session.Session()\n",
    "bedrock_runtime_client = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random session ID\n",
    "def generate_web_session_id(length=16):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choices(characters, k=length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da34765",
   "metadata": {},
   "source": [
    "### Main Function with Observability\n",
    "\n",
    "Let's create our main function that uses the Converse API and is decorated with our observability logger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3da63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bedrock_logs.watch(call_type='Converse-API')\n",
    "def converse_with_model(application_metadata):\n",
    "    model_id = MODEL_ARN\n",
    "    \n",
    "    system_prompts = [{\"text\": \"You are an expert that creates playlists for users. Only return song names and the artist.\"}]\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": application_metadata['question']}]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    inference_config = {\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"maxTokens\": MAX_TOKENS,\n",
    "        \"topP\": TOP_P\n",
    "    }\n",
    "    \n",
    "    guardrail_config = {\n",
    "        \"guardrailIdentifier\": GUARDRAIL_ID,\n",
    "        \"guardrailVersion\": GUARDRAIL_VERSION,\n",
    "        \"trace\": \"enabled\"\n",
    "    }\n",
    "    \n",
    "    response = bedrock_runtime_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        guardrailConfig=guardrail_config\n",
    "    )\n",
    "    \n",
    "    application_metadata['model_response'] = response\n",
    "    return response['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f33359",
   "metadata": {},
   "source": [
    "### Running the Conversation\n",
    "\n",
    "Now, let's run a conversation with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975900af",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Create a list of 3 pop songs by artists from the United Kingdom.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87367cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_metadata = {\n",
    "    'webSessionId': generate_web_session_id(),\n",
    "    'userID': 'User-1',\n",
    "    'customTags': CUSTOM_TAG,\n",
    "    'request_time': datetime.now(pytz.utc).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "    'model_arn': MODEL_ARN,\n",
    "    'question': question\n",
    "}\n",
    "\n",
    "response, log, run_id, observation_id = converse_with_model(application_metadata)\n",
    "\n",
    "print(f\"Model response: {response}\")\n",
    "print(f\"run_id: {run_id}\")\n",
    "print(f\"observation_id: {observation_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037402d",
   "metadata": {},
   "source": [
    "### Collecting Feedback\n",
    "\n",
    "We'll define two functions for collecting feedback at the observation and session levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c42a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bedrock_logs.watch(call_type='observation-feedback')\n",
    "def observation_level_feedback(feedback):\n",
    "    pass\n",
    "\n",
    "@bedrock_logs.watch(call_type='session-feedback')\n",
    "def session_level_feedback(feedback):\n",
    "    pass\n",
    "\n",
    "user_feedback = 'Thumbs-up'\n",
    "observation_feedback_from_front_end = {\n",
    "    'user_id': 'User-1',\n",
    "    'f_run_id': run_id,\n",
    "    'f_observation_id': observation_id,\n",
    "    'actual_feedback': user_feedback\n",
    "}\n",
    "observation_level_feedback(observation_feedback_from_front_end)\n",
    "\n",
    "user_feedback = 'Amazing - this is fast and an awesome way to help the customers!'\n",
    "session_feedback_from_front_end = {\n",
    "    'user_id': 'User-1',\n",
    "    'f_run_id': run_id,\n",
    "    'actual_feedback': user_feedback\n",
    "}\n",
    "session_level_feedback(session_feedback_from_front_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36f8a6",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook demonstrates how to use the customized `observability` module with the AWS Bedrock Converse API. We've shown how to:\n",
    "\n",
    "1. Set up the environment and initialize the BedrockLogs class\n",
    "2. Create a conversation function with observability\n",
    "3. Run a conversation and collect the response\n",
    "4. Implement feedback collection at both the observation and session levels\n",
    "\n",
    "The collected data can be used for analysis, troubleshooting, and improving your application's performance and user experience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
